{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设有大量数据需要处理,使用列表收集数据\n",
    "simulation_data = []\n",
    "\n",
    "# 模拟数据生成过程\n",
    "for sim_id in range(1000):  # 假设有1000轮模拟\n",
    "    for capture in range(0, 1001, 10):  # 捕食数目从0到1000,步长为10\n",
    "        # 这里应该是你的模拟函数或某种数据生成方式\n",
    "        nsteps = capture + 5  # 示例的步数计算\n",
    "        simulation_data.append({\"Environment\": \"Env1\", \"Simulation\": sim_id, \"NCapture\": capture, \"NSteps\": nsteps})\n",
    "\n",
    "# 一次性创建 DataFrame\n",
    "df = pd.DataFrame(simulation_data)\n",
    "\n",
    "# 转换数据类型以节省内存\n",
    "df['NCapture'] = df['NCapture'].astype('int16')\n",
    "df['NSteps'] = df['NSteps'].astype('int32')\n",
    "df['Simulation'] = df['Simulation'].astype('int16')\n",
    "df['Environment'] = df['Environment'].astype('category')\n",
    "\n",
    "# 分组计算平均步数\n",
    "average_nsteps = df.groupby('NCapture').agg({'NSteps': 'mean'}).reset_index()\n",
    "\n",
    "print(average_nsteps)\n",
    "\n",
    "# 可选:保存到 CSV\n",
    "df.to_csv(\"data/nsteps_ncapture.csv\", index=False)\n",
    "average_nsteps.to_csv(\"data/ave_nsteps_ncapture.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将新数据追加到已存在的 CSV 文件中\n",
    "csv_file_path = 'average_nsteps.csv'  # 指定文件路径\n",
    "\n",
    "# 检查文件是否已存在,如果不存在,先写入头部\n",
    "import os\n",
    "if not os.path.isfile(csv_file_path):\n",
    "    new_df.to_csv(csv_file_path, mode='w', index=False)  # 写入头部\n",
    "else:\n",
    "    new_df.to_csv(csv_file_path, mode='a', index=False, header=False)  # 追加数据,不包含头部"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No put-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import sys\n",
    "# 添加到 sys.path\n",
    "sys.path.append('..')\n",
    "import environment\n",
    "from agents.my_policies import GreedyPolicy\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "import yaml\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# 设置环境ID和配置ID\n",
    "env_id = 'PredatorPrey-v0'\n",
    "config_id = 'default_7'\n",
    "\n",
    "# 读取配置文件\n",
    "with open('../params/env_configs.yaml', 'r') as file:\n",
    "    env_config = yaml.safe_load(file)[env_id][config_id]\n",
    "\n",
    "env = gym.make(env_id, **env_config, render_mode='human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../output/checkpoints/default_8/put_back_v0_7680000_steps.zip'\n",
    "smart_policy = PPO.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化环境并运行\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    # 预测动作\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_policy = GreedyPolicy(env.observation_space, env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put-back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
